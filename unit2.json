{
    "pptName": "Unit 2",
    "slides": [
        "```\fUnit 2: Peer-to-Peer Networking2. 1Introduction2. 2P2P Topologies2. 3P2P Applications2. 4P2P and the Internet2. 5Unstructured overlay topology2. 6Structured overlay topologyReading: Chapters 29, Textbook – Forouzan || Unit 2 - 2```",
        "```\f2. 1 Introduction || Unit 2 - 3```",
        "```\fDefinition of P2P SystemsThere is no universally accepted definition of P2P systems, although thereare many definitions, and there are some common characteristics shared bymost P2P systems:A ‘peer’ is a computer that can act as both server and/or client. A P2P system should consist of at least two or more peers. Peers should be able to exchange resources directly among themselves. Such resources include files, storages, information, central processingunit (CPU) power and knowledge. Dedicated servers may or may not be present in a P2P systemdepending on the nature of the applications. P2P systems without dedicated servers are sometimes described as‘pure’ P2P systems. Peers can join and/or leave the system freely.  || Unit 2 - 4```",
        "```\fBenefits of P2P SystemsWorkload is spread to all peersIt is possible to have millions of computers in a P2P network, which can deliverhuge resources and power. Maximize system utilizationMany office computers are not used at all from 5 pm to 9 am in the nextmorning.  P2P computer can use these resources and thus maximize theutilization. No central point of failureE. g. , the Internet and the Web do not have a central point of failure. P2P network will still function when some of its peers are not working properly. Thus it is more fault tolerant than other systems (e. g.  C/S). ScalabilitySince every peer is alike, it is possible to add more peers to the system and scaleto larger networks.  || Unit 2 - 5```",
        "```\fDisadvantages of P2P ComputingThe peer will be more susceptible to hackers’ attacks. It is difficult to enforce standards in P2P systems. A P2P network cannot guarantee that a particular resource will be availableall the time. For example, the owner may shut down his/her computer or delete afile. It is difficult to predict the overall performance of a system. It is difficult to prevent illegal uploading and downloading of copyrightedmaterials. A popular P2P system can generate enormous amount of network traffic. As a result, some universities did not allow their students to accesssome P2P applications inside the campus.  || Unit 2 - 6```",
        "```\f2. 2 P2P Topologies || Unit 2 - 7```",
        "```\fP2P TopologiesCentralizedRingHierarchicalDecentralizedHybrid || Unit 2 - 8```",
        "```\fCentralized TopologyCentralized systems are the most familiar form of topology. Typically seen as the client/server pattern used bydatabases, web servers,and other simple distributed systems. All function and information is centralizedinto one server with many clients connectingdirectly to the server to send and receiveinformation. Many \"peer-to-peer\" applicationsalso have a centralized component. The original Napster's search architecturewas centralized, although the file sharing was not.  || Unit 2 - 9```",
        "```\fRing TopologyA single centralized server cannot handle high clients loadA common solution is to use a cluster of machinesarranged in a ring to act as a distributed servers. Communication between the nodescoordinates state-sharing, to provideidentical functionWith fail-over andload-balancing capabilities. Ring systems are generally built onthe assumption thatthe machines are all nearby on the networkand owned by a single organization.  || Unit 2 - 10```",
        "```\fHierarchical TopologyHierarchical systems have a long history on the InternetThe best-known hierarchical system on the Internetis the Domain Name Service,where authority flows fromthe root name-servers to the serverfor the registered name. The Network Time Protocol (NTP) isa protocol for synchronizing the clocksof computer systems over networksthere are root time servers that have authoritative clocks; othercomputers synchronize to root time servers in a self-organizing tree.  || Unit 2 - 11```",
        "```\fDecentralized TopologyThis is the opposite of centralized topologyAll peers communicate symmetrically and have equal roles. Decentralized systems are not new;the Internet routing architecture islargely decentralized, with theBorder Gateway Protocol betweenvarious autonomous systems. Gnutella is probably the most \"pure\"decentralized system used in practice today || Unit 2 - 12```",
        "```\fHybrid Topology: Centralized + RingReal-world systems often combine several topologies into one system,making a hybrid topology. Nodes typically play multiple rolesin such a system. For example, a node might havea centralized interaction with onepart of the system, while beingpart of a ring with other nodes. Centralized + RingMost web server applications often havea ring of servers for load balancing and failover. The system as a whole is a hybrid: a centralized system for clientswhere the server is itself a ring.  || Unit 2 - 13```",
        "```\fHybrid Topology: Centralized + DecentralizedCentralized + DecentralizedAdvancing an architecture ofcentralized systems embeddedin decentralized systems. Most peers have a centralizedrelationship to a \"supernode\"forwarding all file queries tothis serverBut instead of supernodes beingstandalone servers, they bandthemselves together in adecentralized network, propagating queries.  || Unit 2 - 14```",
        "```\fEvaluating TopologiesManageabilityHow hard is it to keep working, in terms of updating, repairing, and logging?Information coherenceIf a bit of data is found in the system, is that data correct? (Non-repudiation anddata consistency)ExtensibilityHow easy is the system to grow?Fault toleranceHow well can it handle failures?Resistance to legal or political interventionHow hard is it to shut down? (Can be good or bad)SecurityHow hard is the system to be attacked?ScalabilityHow big can the system grow? || Unit 2 - 15```",
        "```\fCentralizedManageableCoherentExtensible✓ System is all in one place✓ All information is in one placeX Resources (CPU/Data) can only beadded to the central systemFault TolerantSecureX Single point of failure✓ Simply only one host that needsto be protectedLawsuit-proofScalableX Easy to shut downLimited by the capacity of the server.  || Unit 2 - 16```",
        "```\fRingManageableCoherentExtensibleFault TolerantSecureLawsuit-proofScalable✓ Typically have a single owner, withrules for relationships✓ Easy logic for stateX Only ring owner can add (a user stillneeds the owner's permission to adda resource like a music file or a Webpage into the ring)✓ Fail-over to next host✓ As long as ring has one ownerX Shut down owner✓ Just add more hosts || Unit 2 - 17```",
        "```\fHierarchicalManageable½ Chain of authorityCoherent½ Cache consistencyExtensible½ Add more leaves, rebalanceFault Tolerant½ the root is still a single pointof failureSecureLawsuit-proofScalable½ It is not just the root that is a riskX Just shut down the root✓ Hugely scalable – DNS || Unit 2 - 18```",
        "```\fDecentralizedManageableCoherentExtensibleFault TolerantSecureLawsuit-proofScalableX Very difficult, many ownersX Difficult, unreliable peers✓ Anyone can join in!✓ RedundancyX Difficult, open research✓ No one to sueTheory – yes : Practice – no || Unit 2 - 19```",
        "```\fCentralized + RingManageable✓ Just manage the ringCoherent✓ As coherent as ringExtensibleX No more than ringFault Tolerant✓ Ring is a huge winSecureLawsuit-proofScalable✓ As secure as ringX Still single place to shut down✓ Ring is a huge winCommon architecture for web applications || Unit 2 - 20```",
        "```\fCentralized + DecentralizedManageableCoherentX Same as decentralized½ Better than decentralizedfewer hosts that are holding authoritative dataExtensible✓ Anyone can still join!Fault Tolerant✓ Plenty of redundancySecureLawsuit-proofScalableX Same as decentralized✓ Still no one to sueLooking very hopefullyBest architecture for P2P networks || Unit 2 - 21```",
        "```\f2. 3 P2P Applications || Unit 2 - 22```",
        "```\fP2P Computing ApplicationsFile sharingImproves data availabilityReplication to compensate for failures. E. g. , Napster, Gnutella, Freenet, KaZaA (FastTrack). Process sharingFor large-scale computationsData analysis, data mining, scientific computingCollaborative environmentsFor remote real-time human collaboration. Instant messaging, shared whiteboards, teleconferencingE. g. , Skype, Messenger.  || Unit 2 - 23```",
        "```\fP2P Technical ChallengesPeer identificationRouting protocolsNetwork topologiesPeer discoveryCommunication/coordination protocolsQuality of serviceSecurity || Unit 2 - 24```",
        "```\fFamous Napster ModelCreated in 1999 by Shawn Fanning, an 18-year-old studentNapster is P2P application network, which gives its members ability to connectdirectly to other members’ computers and search their hard drives for digital musicfiles to share and trade. Members download a software package from Napster and install it on theircomputers. The Napster central computer maintains directories of music files of members whoare currently connected to the network.  These directories are automatically updatedwhen a member logs on or off the network. Whenever a member submits a request to search for a file, the central computerprovides information to the requesting member. The requesting member can then establish a connection directly with anothermember’s computer containing that particular file. The download of the target file takes place directly between the members’computers, bypassing the central computer.  || Unit 2 - 25```",
        "```\fNapster Model || Unit 2 - 26```",
        "```\fNapster ModelOver 36 million people joined the Napster communityIt rapidly accelerated the development and implementation of other P2P models. The limitation is that it can only share music filesIn July 2001, The Recording Industry Association of America (RIAA), ordered toshutdown Napster due to the free copying of copyrighted material.  || Unit 2 - 27```",
        "```\fOther P2P SystemsNapster was ordered to shut down because it maintained a central directoryfor its members. New file-sharing P2P systems bypass the legal problems as they do nothold a central directoryThey do not even need a central server or any company to run the system. Thus, it is impossible to kill the network. These new P2P systems include Gnutella, KaZaA, LimeWire , DirectConnect, etc.  || Unit 2 - 28```",
        "```\fThe network structure of GnutellaThe idea of Gnutella is similar to the ‘searchstrategies’ employed by humans. If you want to get a particular file, you can ask one ofyour friends.  If he/she does not have the file, he/shecan ask his/her friends.  This request will be conveyedfrom one person to another until it reaches someonewho has the file. This piece of information will be routed to youaccording to the original path. Computers in the network have different connectionspeeds. A high-speed computer will connect to manycomputers, while the low-speed computer willconnect to only a few computers. Over the course of time, the network will have ahigh-speed computer in the core.  || Unit 2 - 29```",
        "```\fBitTorrent (Motivation)An analysis by Xerox Research Center indicated that50% of all files for sharing were stored on only 1% of the peers. About 70% of all Gnutella users do not share any files with others. In other word, all they do is ‘download’.  They are referred to as “free loaders”or “free riders”When a peer shares a popular file with othersin a P2P network, it will attract a large volumeof traffic.  And hence this peer needs to paymore bandwidth costs for more clientsA large proportion of freeloaders,will defeat the objective to shareworkload in a P2P network.  || Unit 2 - 30```",
        "```\fBitTorrent (Model)BitTorrent is a P2P protocol, designed by Bram Cohen, for sharing a large file amonga set of peers. The term file-sharing means that instead of download the whole file from one peer,the file can be downloaded from a group of peers,because the file is divided into number of parts that are distributed among thisgroup of peers. File sharing is done in a collaborating process called a torrent. Each peer participating in a torrent downloads chunksof the large file from another peer that has it anduploads chunks of that file to other peers that donot have it. The performance will be improved because there isno way to turn off the upload function of aBitTorrent program when a computer is downloading.  || Unit 2 - 31```",
        "```\fBitTorrent (Model)The set of all peers that takes part in a torrent is referred to as a swarm. A peer in a swarm that has the complete content file is called a seed. A peer that has only part of the file and wants to download the rest is called a leech. In other words, a swarm is a combinationof seeds and leeches. BitTorrent has gone throughseveral versions and implementations. The original one, uses a centralnode called a tracker, to trackthe operation of the swarm. The new versions eliminate thetracker by using DHT (more later).  || Unit 2 - 32```",
        "```\fBitTorrent – How does it work?Now assume a new peer wants to download a content of a common file. The new peer search the Internet for the corresponding metafile of this content.  This fileis called a Torrent file. The Torrent file contains:File name# of chunks (pieces), sizechecksumIP address of the Tracker,…etc. Using this Torrent file, the new peer uses a BitTorrent client application to access thetracker and receives the addresses of some peers in the torrent, normally calledneighbours. The new peer is now part of the torrent and can download and upload pieces of thecontent file. Nothing can prevent a peer from leaving the torrent before it has all the pieces and joininglater or not joining again. The BitTorrent protocol applies a set of policies to provide fairness and to preventoverloading a peer with requests from other peers.  || Unit 2 - 33```",
        "```\fBitTorrent – Policies (1)To avoid overloading and to achieve fairness,each peer needs to limit its concurrent connection to a number of neighbours; the typical value isfour. A peer flags a neighbour as unchoked or choked. It also flags them as interested or uninterested. This means, the provided neighbors list will be divided into unchoked/choked, andinterested/uninterested. The unchoked group is the list of peers that the current peer has concurrently connected to; itcontinuously uploads and downloads pieces from this group. The choked group is the list of neighbours that the peer is not currently connected to but mayconnect to in the future. Every 10 seconds, the current peer tries one peer from the interested but choked group fora better data rate.  If it has a better rate than any of the unchoked peers, their status maybe swapped. This strategy divides the neighbours into subgroups in which those neighbours with compatibledata transfer rates will communicate with each other || Unit 2 - 34```",
        "```\fBitTorrent – Policies (2)To allow a newly joined peer, which does not yet have a piece to share, to alsoreceive pieces from other peers,Every 30 seconds the system randomly promotes a single peer, regardless of itsuploading rate, from the choked/uninterested group and flags it as unchoked. This action is called optimistic unchoking. A balance between the number of pieces that each peer may have is managed by astrategy called the rarest-first. Using this strategy, a peer tries to first download the pieces with the fewestrepeated copies among the neighbours. In this way, these pieces are circulated faster.  || Unit 2 - 35```",
        "```\f2. 4 P2P and the Internet(Overlay, Structured, Unstructured) || Unit 2 - 36```",
        "```\fP2P Overlays and Network ServicesPeers in P2P applications communicate with other peers using messagestransmitted over the Internet or other types of networks. The protocols of various P2P applications have some common features. protocols are constructed at the application layer. peers have a unique identifier, which is the peer ID or peer address. P2P protocols support some type of message-routing capability. a message intended for one peer can be transmitted viaintermediate peers to reach the destination peer.  || Unit 2 - 37```",
        "```\fP2P Overlays and Network ServicesTo distinguish the operation of the P2P protocol at the application layerfrom the behavior of the underlying physical network,the collection of peer connections in a P2P network is calleda P2P overlayNext slide shows the correspondence between peers connecting in anoverlay network with the corresponding nodes in the underlying physicalnetwork || Unit 2 - 38```",
        "```\fPeers form an overlay network (top) uses network connections in the native network (bottom)The overlay organization is a logical view that might not directly mirror the physical network || Unit 2 - 39```",
        "```\fOverlay Networks TypesDepending on how the nodes in a P2P overlay are linked, the overlay network can beclassified as eitherUnstructured or Structured overlay networksUnstructured NetworksThe nodes are linked randomly. A search in unstructured P2P is not very efficient, and a query may not be resolved. (more details later)Gnutella and Freenet are examples of unstructured P2P networks. Structured NetworksUse a predefined set of rules to link nodes so that a query can be effectively andefficiently resolved. The most common technique used for this purpose is the Distributed Hash Table(DHT). One popular P2P file sharing protocol that uses the DHT is BitTorrent.  || Unit 2 - 40```",
        "```\fDistributed Hash Table (DHT)DHT distributes data items (objects) among a set of nodes according to somepredefined rules. Each peer in a DHT-based network becomes responsible for a range of data items. Each data item and the responsible peer is mapped to a point in a large addressspace of size 2m.  (Most of the DHT implementations use m=160)The address space is designed using modular arithmetic, which means that the pointsin the address space is distributed on a circle with 2m points (0 to 2m – 1) usingclockwise direction as shown:Note:1.  Space range is 0 to 2m -12.  Calculation is done modulo 2m(3/4) x 2mAddress spaceof size 2m(1/4) x 2m(1/2) x 2m || Unit 2 - 41```",
        "```\fDHT - Hashing Peer/Object IdentifierThe first step in creating the DHT system is to place all peers on the address spacering. This is normally done by using a hash function that hashes the peer identifier,normally its IP address, to an m-bit integer, called a node ID. node ID = hash (Peer IP address)DHT uses some of the cryptographic hash functions such as Secure Hash Algorithm(SHA-1) that are collision resistant. The name of the object (for example, a file) to be shared is also hashed to an m-bitinteger in the same address space, called a key. key = hash (Object name)In the DHT an object is normally related to the pair (key, value) in which the key isthe hash of the object name and the value is the object or a reference to theobject.  || Unit 2 - 42```",
        "```\fDHT - Storing the ObjectThere are two strategies for storing the object:A direct method:The object is stored in the node whose ID is closest to the key in the ring. The term closest is defined differently in each protocol. An indirect method:The peer that owns the object keeps the object, but a reference to theobject is created and stored in the node whose ID is closest to the keypoint. This means, the physical object and the reference to the object are stored intwo different locations (peers). Most DHT systems use the indirect method due to efficiency. In either case, a search mechanism is needed to find the object if the name of theobject is given.  || Unit 2 - 43```",
        "```\fDHT - ExampleThe normal value of m is 160, for the purpose of demonstration, we use m = 5. The node N5 with IP address 110. 34. 56. 23 has a file named “SE3314b-Assignment“ that it wantsto share with its peers. The file is stored in N5, the key of the file is k14, butthe reference to the file is stored in node N17. SE3314b-AssignmentLegend5200key = hash (object name)node = hash (IP address)point (potential key or node)(110. 34. 56. 23)N2N29N5N25Key14Reference(110. 34. 56. 23:5200)N10N20N17(129. 100. 224. 11)5=hash (110. 34. 56. 23)ID space ofsize 25 (m=5)K1414=hash (“SE3314b-Assignment”) || Unit 2 - 44```",
        "```\f2. 5 Unstructured overlay topology || Unit 2 - 45```",
        "```\fUnstructured OverlayAn unstructured P2P network is formed when the overlay links are establishedarbitrarily. Unstructured overlays, for example Gnutella,organize nodes into a random graph anduse floods or random walks to discover data stored by overlay nodes. Each node visited during a flood or random walk evaluates the query locally on thedata items that it stores. Unstructured overlays does not impose any constraints on the node graph or on dataplacement,for example, each node can choose any other node to be its neighbour in theoverlayUnstructured overlays cannot find rare data items efficiently, and it does notguarantee that an object can be found if it exists in the overlay.  || Unit 2 - 46```",
        "```\fFlooding and Expanding RingWhen each peer keeps a list of its neighbors,and when this neighbor relations are transitive,we will have connectivity graphs such as the one shown in this figureIn this particular graph:peers have degree from 2 to 5Increasing the degree reducesthe diameter of the overlay, butrequires more storage at each peer. Peers can exchange messages withother peers in its neighbor list. Message can be a query that containsthe search criteria, such as a filename or keywords. We don’t know which peers in the overlay have the information, so to whom thequery will be sent? || Unit 2 - 47```",
        "```\fFlooding AlgorithmSimple algorithm: (flooding)Peer could try sending a query to all its neighbor.  If the neighbor peers don’thave the information, they can in turn forward the request to their neighbors,and so on. But, how to prevent messages from circulating endlessly?Using message identifiersAttach (TTL) value toa message to limits its lifetime.  || Unit 2 - 48```",
        "```\fFlooding AlgorithmFloodForward(Query q, Source p)// have we seen this query before?if(q. id  oldIdsQ) return // yes, drop itoldIdsQ = oldIdsQ  q. id // remember this query// expiration time reached?q. TTL = q. TTL – 1if q. TTL  0 then return // yes, drop it// no, forward it to remaining neighborsforeach(s  Neighbors) if(s  p) FloodForward(q,s)Each peer has a list of neighbors. It initializes its list of neighbors when it joins the overlayfor example, by getting a copy of the neighbor list of the first peer that it connects toWhen the query is satisfied at some peer, a response message is sent to the requesting peer. If the object is not found quickly, the flooding mechanism continues to propagate the querymessage along other paths until the TTL value expires or the query is satisfied.  || Unit 2 - 49```",
        "```\fExpanding RingFlooding mechanism creates substantial redundant messaging, which is inefficient forthe network. We may start the search with a small TTL value.  If this succeeds, the search stops. Otherwise, the TTL value is increased by a small amount and the query is reissued. This variation of flooding is called iterative deepening or expanding ring || Unit 2 - 50```",
        "```\fRandom WalkTo avoid the message overhead of flooding, unstructured overlays can use some typeof random walk. In random walk a single query message is sent to a randomly selected neighbor. The message has a TTL value that is decremented at each hop. If the desired object is found, the search terminates. Otherwise the query fails, by a timeout or an explicit failure messageThe same process may be repeated to another randomly chosen path. To improve the response time, several random walk queries can be issued in parallel || Unit 2 - 51```",
        "```\fRandom Walk AlgorithmRandomWalk(source, query, TTL)if (TTL > 0) {TTL = TTL – 1// select next hop at random, don’t send back to sourcewhile((next_hop = neighbors[random()]) == source){}RandomWalk(source, query, TTL) || Unit 2 - 52```",
        "```\fSummaryUnstructured overlays have been used in several widely used filesharing systems, despite their inefficiencies. In the research community there has been much effort to increasetheir performance and reduce overhead. Structured overlays, emerged to address limitations of unstructuredoverlays by combining a specific geometrical structure withappropriate routing and maintenance mechanisms.  || Unit 2 - 53```",
        "```\f2. 6 Structured overlay topology || Unit 2 - 54```",
        "```\fMotivation and CategoriesThe earliest peer-to-peer systems used unstructured overlays that wereeasy to implement but had inefficient routing and an inability to locate rareobjects. These problems turned the attentions to design overlays with routingmechanisms thatare deterministic and that can provide guarantees on the ability tolocate any object stored in the overlay. The large majority of these designs used overlays with a specific routinggeometry and are called structured overlays.  || Unit 2 - 55```",
        "```\fStructured overlays & Directed SearchesIdea:Assign particular nodes to hold particular content (or pointers to it, likean information booth)When a node wants that content, go to the node that is supposed tohave or know about itChallenges:Distributed: want to distribute responsibilities among existing nodes inthe overlayAdaptive: nodes join and leave the P2P overlaydistribute knowledge responsibility to joining nodesredistribute responsibility knowledge from leaving nodes || Unit 2 - 56```",
        "```\fStructured overlays & Directed SearchesStructured overlays support key-based routing such thatobject identifiers are mapped to the peer identifier address space andan object request (lookup message) is routed to the nearest peer inthe peer address space. P2P systems using key-based routing are called distributed object locationand routing (DOLR) systems. A specific type of DOLR is a distributed hash table (DHT)In this Unit, we introduce three of these protocols:Pastry,Kademlia, andChord.  || Unit 2 - 57```",
        "```\fDHT - ExampleThe normal value of m is 160, for the purpose of demonstration, we use m = 5. The node N5 with IP address 110. 34. 56. 23 has a file named “SE3314b-Assignment“ that it wantsto share with its peers. The file is stored in N5, the key of the file is k14, butthe reference to the file is stored in node N17. SE3314b-AssignmentLegend5200key = hash (object name)node = hash (IP address)point (potential key or node)(110. 34. 56. 23)N2N29N5N25Key14Reference(110. 34. 56. 23:5200)N10N20N17(129. 100. 224. 11)5=hash (110. 34. 56. 23)ID space ofsize 25 (m=5)K1414=hash (“SE3314b-Assignment”) || Unit 2 - 58```",
        "```\fPastryPastry is designed by Antony Rowstron and Peter Druschel in 2001, and uses DHT. Nodes and data items are identified by m-bit IDs that create an identifier space ofsize 2m points distributed in a circle in the clockwise direction. The common value for m is 128.  The protocol uses the SHA-1 hashing algorithmwith m = 128. In Pastry, an identifier is seen as an n-digit string in base 2b in which b is normally 4and n = (m/b). For instance, an identifier is a 32-digit number in base 16 (hexadecimal). A key is stored in the node whose identifier is numerically closest to the key || Unit 2 - 59```",
        "```\fPastry - RoutingEach node in Pastry can resolve a query using two entities: a routing table and a leafset. (2b) columns. when m = 128 , b = 4, we have 16 columnsRouting Tablen rows. when m =128 , b = 4,we have 32(128/4) rowsCommonprefix length31For node N, Table [i, j], gives the ID of a node (if it exists) that shares the i leftmost digits withthe ID for N and its (i+1)th digit has a value of j. The first row, row 0, shows the list of live nodes whose identifiers have no common prefix with N. The last row, row 31, shows the list of all live nodes that share the leftmost 31 digits with nodeN; only the last digit is different.  || Unit 2 - 60```",
        "```\fRouting Table, ExampleAssume the node N ID is (574A234B12E374A2001B23451EEE4BCD)16then the value of the Table [2, D] can be the identifier of a node such as (57D. . . ). Commonprefix length57D…31Note that the leftmost two digits are 57, which are common with the first two digits of N,but the next digit is D, the value corresponding to the Dth column. If there are more nodes with the prefix 57D, the closest one, according to the proximitymetric, is chosen, and its identifier is inserted in this cell. The proximity metric is a measurement of closeness determined by the application thatuses the network. It can be based on the number of hops between the two nodes, the round-trip timebetween the two nodes, or other metrics.  || Unit 2 - 61```",
        "```\fPastry - RoutingLeaf SetAnother entity used in routing is a set of 2b identifiers (the size of a row in therouting table) called the leaf set. The left half of the set is a list of IDs that are numerically smaller than thecurrent node IDThe right half is a list of IDs that are numerically larger than the current node ID. The leaf set gives the identifier of 2b-1 live nodes located before the current nodein the ring and the list of 2b-1 nodes located after the current node in the ring.  || Unit 2 - 62```",
        "```\fRouting table & Leaf Set, ExampleK3222N0002K3133K3122Node ID 22102200 2203 2213 2230Leaf set31220 0202 12121 2013 210322302 22032213Routing tableN32002013 2103 2203 2210Leaf set31220 0202 11031 2013 2103221022302203Routing tableN0101N0202N3122K0203N0301N0302N0321K2233Node ID 2200Node ID 0302m=80202 0301 0321 1000Leaf set1302 2001 31220002 0101 020203210301Routing tableN1000b=2N2230N1103N2213N2210N2203N2200N2103K1110N1212N1220N2013K1213N2001N1302K2011Node ID 20011220 1302 2013 2103Leaf set32000 0101 10002103 22002013Routing table || Unit 2 - 63```",
        "```\fPastry – Lookup OperationPastry - lookup: given a key, it finds the node that stores the information about thekey or the key itself. Lookup (key)if (key is in the range of N's leaf set)forward the message to the closest node in the leaf setelseroute (key, Table)route (key, Table)p = length of shared prefix between key and Nv = value of the digit at position p of the key// Position starts from 0if (Table [p, v] exists)forward the message to the node in Table [p, v]elseforward the message to a node sharing a prefix as long asthe current node, but numerically closer to the key.  || Unit 2 - 64```",
        "```\fLookup Operation, Example (1)K3222N0002N3200K3133K3122Node ID 22102200 2203 2213 2230Leaf set31220 0202 12121 2013 210322302 22032213Routing table(2) Ask 2013about key20112013 2103 2203 2210Leaf set31220 0202 11031 2013 2103221022302203Routing tableN0101N0202N3122K0203N0301N0302N0321K2233Node ID 2200Node ID 0302m=8N2230N2213N1000b=2N1103(1) Who’sresponsiblefor key 2011N2210N2203N2200N2103K1110N1212N1220N2013K1213N2001N1302K2011(3) Yes, Ihave the key20110202 0301 0321 1000Leaf set1302 2001 31220002 0101 020203210301Routing tableNode ID 20011220 1302 2013 2103Leaf set32000 0101 10002103 22002013Routing table || Unit 2 - 65```",
        "```\fLookup Operation, Example (2)(3) Yes, Ihave the key0203(1) Who’sresponsiblefor key 0203(2) Ask 0202about key0203 || Unit 2 - 66```",
        "```\fPastry – Join OperationThe process of joining the ring in Pastry is as follows:The new node, X, should know at least one node N0, which should be close to X, andsend a join message to it.  (we assume that N0 has no common prefix with X)1.  Node N0 sends the contents of its row 0 to node X.  Since the two nodes have nocommon prefix, node X uses the appropriate parts of this information to build its row 0. 2.  Node N0 call a lookup operation with X’s ID as a key, which will forward the joinmessage to a node, N1, whose identifier is closest to X. 3.  Node N1 sends the contents of its row 1 to node X.  Since the two nodes have onecommon prefix. 4.  Node N1 then call a lookup operation with X’s ID as a key, which will forward the joinmessage to a node, N2, whose identifier is closest to X. 5.  The process continues until the routing table of node X is complete. 6.  The last node in the process, which has the longest common prefix with X, also sends itsleaf set to node X, which becomes the leaf set of X.  || Unit 2 - 67```",
        "```\fJoin Operation, Example2212joinN00302Row 0join2001Row 1join2200Row 2join2210Row 3Node ID 22122200 2203 2213 2230Leaf set13023122210322302213Routing tableLeaf setA new node X with node ID N2212 uses the information in four nodes as shown to create itsinitial routing table and leaf set for joining the ring. We assume that node 0302 is a nearby node to node 2212 based on the proximity metric.  || Unit 2 - 68```",
        "```\fPastry – Leave (or Fail) OperationEach Pastry node periodically tests the liveliness of the nodes in its leaf set androuting table by exchanging probe messages. If a local node finds that a node in its leaf set is not responding to the probemessage, it assumes that the node has failed or departed. The local node then contacts the live node in its leaf set with the largest identifierand repairs its leaf set with the information in the leaf set of that node. If a local node finds that a node in its routing table, Table [i, j], is not responsive tothe probe message, it sends a message to a live node in the same row and requeststhe identifier in Table [i, j] of that node. This identifier replaces the failed or departed node.  || Unit 2 - 69```",
        "```\fKademliaKademlia, is a DHT peer-to-peer network that is designed by Petar Maymounkov andDavid Mazires, in 2002. Kademlia routes messages based on the distance between nodes. The distance between the two identifiers (nodes or keys) is measured as the bitwiseexclusive-or (XOR) between them. For instance, if x and y are two identifiers, the distance between them is defined as:distance (x, y) = x  yThis distance function has the following properties:xx=0The distance between a node and itself is zero. x  y > 0 if x ≠ yThe distance between any two distinct nodes is greater than zero. xy=yxThe distance between x and y is the same as between y and x. x  z ≤ x  y + y  z Triangular relationship is satisfied.  || Unit 2 - 70```",
        "```\fKademlia – Identifier spaceNodes and data items are m-bit identifiers that create an identifier space of 2m pointsdistributed on the leaves of a binary tree. The protocol uses the SHA-1 hashing algorithm with m = 160. For example: if m = 4, we have 16 IDs distributed on the leaves of a binary tree as:11110000N0N3 K3 K4N1N5N6K7 N8K9N11K12N15Tree rootN0N1N3 K3K4N5N6K7N8K9N11K12N15k3 is stored in N3 because 3  3 = 0.  k7 is stored in N6 not in N8 because 6  7 = 1 but7  8 = 15.  k12 is stored in N15 not in N11 because 11  12 = 7, but 12  15 = 3.  || Unit 2 - 71```",
        "```\fKademlia – Routing tableKademlia keeps only one routing table for each node; there is no leaf set. Each node N divides the binary tree into m subtrees. A subtree i includes nodes that share i leftmost bits (common prefix P) with the anode N, and does not include the node N itself. For example, the node N5 divides our previous tree as follows:P1P3P2P00101 || Unit 2 - 72```",
        "```\fKademlia – Routing tableRouting TableThe routing table is made of m rows but only one column, as follows. Commonprefix lengthIdentifiersClosest node(s) in subtree with common prefix of length 0Closest node(s) in subtree with common prefix of length 1Closest node(s) in subtree with common prefix of length 2m -1Closest node(s) in subtree with common prefix of length m - 1The idea is the same as that used by Pastry, but the length of the common prefix is basedon the number of bits instead of the number of digits in base 2b || Unit 2 - 73```",
        "```\fRouting Table, ExampleLet us find the routing table for our previous Example.  To make the example simple, we assumethat each row uses only one identifier. P3P2To updaterow 20000N8N5N3N1N0To updaterow 0To updaterow 1To updaterow 3Node N0P0P1N8 is theclosest nodeto N0N5 is theclosest nodeto N0N1N3 K3K4N5N6K7N8K9N11K12N15 || Unit 2 - 74```",
        "```\fRouting Table, ExampleLet us find the routing table for our previous Example.  To make the example simple, we assumethat each row uses only one identifier. P3P2P0P10001Node N0N8N5N3N1N0Node N1N1N8N5N3N0N3 K3K4N5N6K7N8K9N11K12N15 || Unit 2 - 75```",
        "```\fRouting Table, ExampleLet us find the routing table for our previous Example.  To make the example simple, we assumethat each row uses only one identifier. P2P3P0P10011Node N0N8N5N3N1N0Node N1N1N8N5N3N0Node N30 N111 N62 N1N3 K3K4N5N6K7N8K9N11K12N15 || Unit 2 - 76```",
        "```\fRouting Table, ExampleLet us find the routing table for our previous Example.  To make the example simple, we assumethat each row uses only one identifier. P3P1P2P00101Node N0N8N5N3N1N0Node N1N1N8N5N3N0Node N3Node N50 N111 N62 N10 N151 N12 N6N3 K3K4N5N6K7N8K9N11K12N15 || Unit 2 - 77```",
        "```\fRouting Table, ExampleLet us find the routing table for our previous Example.  To make the example simple, we assumethat each row uses only one identifier. P2P1P3P00111Node N0N8N5N3N1N0Node N1N1N8N5N3N0Node N3Node N5Node N60 N111 N62 N10 N151 N12 N60 N151 N32 N5N3 K3K4N5N6K7N8K9N11K12N15 || Unit 2 - 78```",
        "```\fRouting Table, ExampleLet us find the routing table for our previous Example.  To make the example simple, we assumethat each row uses only one identifier. P0P3P2P11000Node N0N8N5N3N1N0Node N1N1N8N5N3N0Node N3Node N5Node N6Node N80 N111 N62 N10 N151 N12 N60 N151 N32 N50 N01 N152 N11N3 K3K4N5N6K7N8K9N11K12N15 || Unit 2 - 79```",
        "```\fRouting Table, ExampleLet us find the routing table for our previous Example.  To make the example simple, we assumethat each row uses only one identifier. P0P2P3P11011Node N0N8N5N3N1N0Node N1N1N8N5N3N0Node N3Node N5Node N6Node N8Node N110 N111 N62 N10 N151 N12 N60 N151 N32 N50 N01 N152 N110 N31 N152 N8N3 K3K4N5N6K7N8K9N11K12N15 || Unit 2 - 80```",
        "```\fRouting Table, ExampleLet us find the routing table for our previous Example.  To make the example simple, we assumethat each row uses only one identifier. P0P2P1P31111Node N0N8N5N3N1N0Node N1N1N8N5N3N0Node N3Node N5Node N6Node N8Node N11Node N150 N111 N62 N10 N151 N12 N60 N151 N32 N50 N01 N152 N110 N31 N152 N80 N61 N11N3 K3K4N5N6K7N8K9N11K12N15 || Unit 2 - 81```",
        "```\fLookup Operation, Example (1)We assume node N0 (0000)2 receives a lookup message to find the node responsible for k12(1100)2. Node N0N8N5N3N1N00000(1) Who’sresponsible forkey K12 (1100)Node N1N8N5N3N0Node N3Node N5Node N6Node N8Node N11Node N150 N111 N62 N10 N151 N12 N60 N151 N32 N50 N01 N152 N110 N31 N152 N80 N61 N11N3 K30011N10001(2) AskN8 aboutK12K4N50101N60110K7N81000K9(3) AskN15 aboutK12N111011K12N151111(4) Yes, Ihave the keyK12 (1100)The length of the common prefix between the N0 and K12 is 0.  N0 sends the message to thenode in row 0 of its routing table, node N8. In N8, the length of the common prefix is 1.  It checks row1 and send the query to N15, which isresponsible for k12. The routing process is terminated.  The route is N0 → N8 → N15.  || Unit 2 - 82```",
        "```\fLookup Operation, Example (2)We assume node N5 (0101)2 receives a lookup message to find the node responsible for k7(0111)2. Node N0N8N5N3N1N00000Node N1N8N5N3N0Node N3Node N5Node N6Node N8Node N11Node N150 N111 N62 N10 N151 N12 N60 N151 N32 N50 N01 N152 N110 N31 N152 N80 N61 N11N3 K30011N10001(2) AskN6 aboutK7K4N50101(1) Who’sresponsible forkey K7 (0111)N60110K7N81000K9N111011K12N151111(3) Yes, Ihave the keyK7 (0111)The length of the common prefix between the N5 and K7 is 2.  N5 sends the message to the nodein row 2 of its routing table, node N6, which is responsible for k7. The routing process is terminated.  The route is N5 → N6.  || Unit 2 - 83```",
        "```\fLookup Operation, Example (3)We assume node N11 (1011)2 receives a lookup message to find the node responsible for k4(0100)2. Node N0N8N5N3N1N00000Node N1N8N5N3N0N10001Node N3Node N5Node N6Node N8Node N11Node N150 N111 N62 N10 N151 N12 N60 N151 N32 N50 N01 N152 N110 N31 N152 N80 N61 N11(3) AskN6 aboutK4N3 K30011K4N50101(5) Yes, Ihave the keyK4 (0100)N60110K7(4) AskN5 aboutK4N81000K9(2) AskN3 aboutK4N111011K12N151111(1) Who’sresponsible forkey K4 (0100)The length of the common prefix between the N11 and K4 is 0. N11 sends the message to the node in row 0 of its routing table, node N3. In N3, The length of the common prefix between the two identifiers is 1, the message sent to N6. In N6, The length of the common prefix between the two identifiers is 2, the message sent to N5,which is responsible for k4. The routing process is terminated.  The route is N11 → N3 → N6 → N5.  || Unit 2 - 84```",
        "```\fKademlia – K-BucketsFor more efficiency, Kademlia requires that each row in the routing table keeps atleast up to K=20 nodes from the corresponding subtree. For this reason, each row in the routing table is referred to as a k-bucket. Having more than one node in each row allows the node to use an alternative nodewhen a node leaves the network or fails. Kademlia keeps those nodes in a bucket that has been connected in the network fora long time.  || Unit 2 - 85```",
        "```\fKademlia – More operationsJoin operationAs in Pastry, a node that needs to join the network needs to know at least oneother node. The joining node sends its identifier to the node as though it is a key to befound.  The response it receives allows the new node to create its k-buckets. Leave operationWhen a node leaves the network or fails, other nodes update their k-bucketsusing the lookup process.  || Unit 2 - 86```",
        "```\fChordChord was published by Stoica et al.  in 2001. Chord uses m-bit number to identify the data items denoted as k (for key) and toidentify the peers denoted as N (for node).  . The identifier space then of size 2m points distributed in a circle in the clockwisedirection. All arithmetic in the identifier space is done modulo 2m. Chord recommends the cryptographic hash function SHA-1 for the identifier spacegeneration.  SHA-1 produces output of fixed length equal to 160 bits. The closest peer with N ≥ k is called the successor of k and hosts the value (k, v). where, k is the key (hash of the data name) and v is the value (informationabout the peer that has the actual object).  || Unit 2 - 87```",
        "```\fChord – Finger tableAny node should be able to resolve a query/lookup that asks for the node identifierresponsible for a given key. If a node has no information about this key it forward the query to another nodethat may know. To do forwarding, each node needs to know about m successors nodes and onepredecessor node. These information are saved in a routing table called Finger table. A Finger tableof the node NTarget keySuccessor of target keyInformation about successorN+1Successor of N+1IP address and port of successorN+2Successor of N+2IP address and port of successorN+4Successor of N+4IP address and port of successorN + 2i-1Successor of N + 2i-1IP address and port of successor || Unit 2 - 88```",
        "```\fFinger table - exampleConsider a ring with few nodes and m=5, to make the example simpler. We show only the successor columnfrom the Finger table for and keys. Pre: N25K31Pre: N201 N52 N53 N54 N55 N10K4N25FingerPre: PredecessorFinger[1]: SuccessorN20Pre: N121 N252 N253 N254 N55 N5FingerFingerN5K26N10N10N10N20N25Pre: N5K7K9N10N12K16N12N12N20N20N5FingerK14Note that:• N5 is responsible forK26, K31, K4. • N10 is responsiblefor K7, K9. • N20 is responsiblefor K14, K16. Pre: N10N20N20N20N20N5FingerLegendkey = hash (object name)node = hash (IP address)point (potential key or node) || Unit 2 - 89```",
        "```\fChord – Lookup OperationIn Chord, the lookup operation is used to find where an object is located among theavailable peers in the ring. To find the object, a peer need to know the node that is responsible for that object(the peer that stores reference to that object). We know that, a peer that is the successor of a set of keys in the ring is theresponsible peer for those keys. Finding the responsible node is actually finding the successor of a key. To find the successor of a key, the lookup operationfirst find the predecessor of the key (using find_predecessor function), andthen from the predecessor node it finds the next node in the ring which is thevalue of “finger [1]”. If the key is located far from the current node, the node needs the help of othernodes to find the predecessor (using find_closest_predecessor function). Next slide shows the code for the lookup operation.  || Unit 2 - 90```",
        "```\fChord – Lookup OperationsWho’sresponsiblefor key K14Lookup (key)if (the current node N is responsible for the key)return (N’s ID)elsereturn find_successor (key)find_successor (id)x= find_ predecessor (id)return x. finger[1]find_predecessor (id) {x= Nwhile (id  (x, x. finger[1]) {x = x. find_closest_predecessor (id)return xfind_closest_predecessor (id) {for (i = m downto 1) {if (finger [i]  (N, id))return (finger [i])return N// N is the current node// Let x find it//N is the current node//The node itself is closest predecessor || Unit 2 - 91```",
        "```\fChord – Stabilize OperationLeaving and Joining of a node or a group of nodes may destabilize the ring. Chord defines an operation called stabilize to address this issue so that:Each node in the ring periodically uses stabilizeto validate its information about its successor andlet the successor validate its information about its predecessor. In other words,1.  Node N uses the value of finger[1], S, to ask node S to return its predecessor, P. 2.  If the return value, P, from this query is between N and S, this means that thereis a node with ID equals P that lies between N and S. 3.  Then node N makes P its successor and notifies P to make node N itspredecessor || Unit 2 - 92```",
        "```\fChord – Stabilize OperationStabilize ( )P= finger[1]. Pre//Ask the successor to return its predecessorif(P  (N, finger[1]))finger[1] =Pfinger[1]. notify (N)// P is the possible successor of N// Notify P to change its predecessorNotify (x)if (Pre = null or x  (Pre, N))Pre = x || Unit 2 - 93```",
        "```\fChord – Fix_Finger OperationDestabilization may change the finger table of up to m nodes. Chord defines a fix_finger function to update its finger tables. Each node in the ring must periodically call this function. To avoid traffic on the system, each node must only update one of its fingers in eachcall.  This finger is chosen randomly. Fix_Finger ()Generate (i  (1, m])finger[i] =find_successor (N + 2// Randomly generate i such that 1< i ≤ mi– 1)// Find value of finger[i] || Unit 2 - 94```",
        "```\fChord – Join OperationWhen a new node (N) joins the ring, it uses the join operation. Join function needs to know an ID of another node (say x) to find the successor ofthe new node and set its predecessor to null. It immediately calls the stabilize function to validate its successor. The new node then asks the successor to call the move-key function that transfersthe keys that the new node is responsible for. Join (x)Initialize (x)finger[1]. Move_Keys (N)Initialize (x)Pre = nullif (x = null) finger[1] = Nelse finger[1] = x.  Find_Successor (N)Move_Keys (x)for (each key k)if (x  [k, N)) move (k to node x)// N is the current nodeNote that, after this operation, the finger table ofthe new (joined) node is empty and the finger tableof up to m predecessors is out of date. The stabilize and the fix-finger operations that runperiodically after this event will gradually stabilizethe system.  || Unit 2 - 95```",
        "```\fJoin Operation - ExamplePre: N201 N52 N53 N54 N55 N10FingerN17N17Pre: N121 N252 N253 N254 N55 N5Finger1.  N17 needs to join with the help of N5. 2.  N17 uses Initialize (5) – to set its predecessor to null and itssuccessor (finger[1]) to N20. 3.  N17 then asks N20 to send k14 and k16 to N17 because N17 is nowresponsible for these keys4.  N17 uses stabilize to asks N20 to change its predecessor to N175.  When N12 uses stabilize, the predecessor of N17 is updated to N126.  Finally, when some nodes use fix-finger, the finger table of nodesN17, N10, N5, and N12 is changedPre: N25K31K4N5K26N25Pre: PredecessorFinger[1]: SuccessorK22N20N12Pre: nullN20N25N25N05N10N10N10N20N25N17Pre: N5FingerN17K9N10N12N17 K16 K141 N20K7N12N12N20N20N5FingerPre: N10N20N20N20N20N5N17N17N17FingerFinger || Unit 2 - 96```",
        "```\fChord – Leave (or Fail) OperationWhen a peer leaves the ring or the peer fails, the status of the ring will be disruptedunless the ring stabilizes itself. Each node exchanges ping and pong messages with neighbours to find out if they arealive. When a node does not receive a pong message in response to its ping message, thenode knows that the neighbour is dead. The node that detects the problem can immediately launch these stabilize and fixfinger operations. Note that, the data managed by the node that left or failed is no longer available. Therefore, Chord requires that data and references be duplicated on othernodes.  || Unit 2 - 97```",
        "```\fLeave Operation - ExampleN12N12N12To leaveN12N51.  Node N5 finds out about N10's departure when it does not receive apong message to its ping message. 2.  Node N5 changes its successor (finger[1]) to N12. 3.  Node N5 immediately launches the stabilize function and asks N12 tochange its predecessor to N5. 4.  Hopefully, k7 and k9, which were under the responsibility of N10,have been duplicated in N12 before the departure of N10. 5.  After a few calls of fix-finger, nodes N5 and N25 update their fingertables as shown in the figure.  || Unit 2 - 98```"
    ]
}